{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from data_quality_utils import Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# suppress warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from datasette\n",
    "datasette_base_url = \"https://datasette.planning.data.gov.uk/digital-land.csv\"\n",
    "\n",
    "query = \"\"\"\n",
    "select *\n",
    "from source as s\n",
    "left join organisation as o\n",
    "on s.organisation=o.organisation\n",
    "where s.collection = \"conservation-area\"\n",
    "\"\"\"\n",
    "encoded_query = urllib.parse.urlencode({\"sql\": query})\n",
    "\n",
    "r = requests.get(f\"{datasette_base_url}?{encoded_query}\", auth=(\"user\", \"pass\"))\n",
    "\n",
    "filename = \"datasette_data.csv\"\n",
    "with open(filename, \"wb\") as f_out:\n",
    "    f_out.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by organisation as we're looking for one page per council\n",
    "data = (\n",
    "    pl.read_csv(filename)\n",
    "    .group_by(\"name\")\n",
    "    .agg(pl.col(\"website\").first(), pl.col(\"documentation_url\"))\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_urls(crawl_data, prompt, num_results=None):\n",
    "    \"\"\"\n",
    "    Embeds crawled webpage data, computes similarity to a given prompt, and returns the top N\n",
    "    most similar pages.\n",
    "\n",
    "    Parameters:\n",
    "    - crawl_data (list of tuples): A list of tuples containing (url, markdown) for each crawled page.\n",
    "    - prompt (str): The text prompt to compare against the crawled page embeddings.\n",
    "    - num_results (int, optional): The number of top similar pages to return. If None, returns all pages.\n",
    "\n",
    "    Returns:\n",
    "    - polars.DataFrame: A DataFrame containing:\n",
    "        - \"url\": The webpage URL.\n",
    "        - \"markdown\": The extracted markdown content.\n",
    "        - \"embedding\": The computed embedding for the content.\n",
    "        - \"similarity\": The cosine similarity score with the prompt.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for url, markdown in crawl_data:\n",
    "        embedding = embedding_model.encode(markdown, convert_to_numpy=True).tolist()\n",
    "        res.append((url, markdown, embedding))\n",
    "\n",
    "    crawl_df = pl.DataFrame(res, schema=[\"url\", \"markdown\", \"embedding\"], orient=\"row\")\n",
    "    embeddings = np.stack(crawl_df[\"embedding\"].to_list())\n",
    "\n",
    "    prompt_embedding = np.array(\n",
    "        embedding_model.encode(prompt, convert_to_numpy=True), dtype=\"float64\"\n",
    "    )\n",
    "\n",
    "    # get similarity scores\n",
    "    sim = util.cos_sim(\n",
    "        prompt_embedding.astype(np.float32), embeddings.astype(np.float32)\n",
    "    )\n",
    "    # get indices of top n most similar urls\n",
    "    if not num_results:\n",
    "        num_results = len(crawl_df)\n",
    "    indices = np.argsort(sim).numpy().flatten()[: -num_results - 1 : -1]\n",
    "    sorted_df = crawl_df[indices].with_columns(\n",
    "        similarity=np.sort(sim).flatten()[: -num_results - 1 : -1]\n",
    "    )\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_results(sorted_df, num_results):\n",
    "    # print top n urls with similarity scores\n",
    "    print(\"\\nTop Similar Pages:\\n\" + \"=\" * 40)\n",
    "    for i in range(min(num_results, len(sorted_df))):\n",
    "        url = sorted_df.get_column(\"url\")[i]\n",
    "        score = sorted_df.get_column(\"similarity\")[i]\n",
    "        print(f\"{i+1}. {url.ljust(60)} | Similarity: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_council(\n",
    "    council_names,\n",
    "    max_depth=6,\n",
    "    keyword_scorer=None,\n",
    "    filters=None,\n",
    "    prompt=\"A page about conservation areas.\",\n",
    "    cache_enabled=False,\n",
    "    num_results=10,\n",
    "):\n",
    "    crawler = Crawler(\n",
    "        max_depth=max_depth,\n",
    "        keyword_scorer=keyword_scorer,\n",
    "        filters=filters,\n",
    "        cache_enabled=cache_enabled,\n",
    "    )\n",
    "\n",
    "    for council_name in council_names:\n",
    "        council_data = data.filter(pl.col(\"name\").str.contains(council_name))\n",
    "        full_name = council_data.get_column(\"name\")[0]\n",
    "        homepage = council_data.get_column(\"website\")[0]\n",
    "        prompt = prompt.format((full_name).replace(\"\\n\", \"\"))\n",
    "        print(\"=\" * 40 + f\"\\nProcessing {full_name}...\\n\")\n",
    "\n",
    "        # crawl url\n",
    "        crawl_data = await crawler.deep_crawl(homepage)\n",
    "\n",
    "        # get markdown embeddings\n",
    "        sorted_df = get_similar_urls(crawl_data, prompt)\n",
    "\n",
    "        pretty_print_results(sorted_df, num_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Our approach\n",
    "\n",
    "Our approach involves 2 main steps: a web crawler and an embedding similarity search. Below is a description of these steps.\n",
    "\n",
    "### Web crawler\n",
    "\n",
    "The web crawler takes a homepage URL of an organisation (council website) and crawls it to look for pages talking about conservation areas.\n",
    "\n",
    "The crawler will look for links on a single page, put them in a queue and then iteratively check them until it finds what it was looking for or it reaches a stopping criterion, such as maximum depth (how many clicks away from home page). \n",
    "\n",
    "In order to save time, we can define some scorers or filters which tell the crawler which pages to prioritise or ignore. In this case, some common patterns of what a user needs to click to get to the page of interest are _\"planning\"_, _\"building\"_, _\"heritage\"_ or _\"conservation\"_.\n",
    "\n",
    "The crawler uses a *\"best first strategy\"*, which utilises the scorers or filters to visit most relevant sites first, rather than a depth-first or breath-first search.\n",
    "\n",
    "The crawler extracts the HTML from the pages and turns them into markdown. This is because it's more readable and easier to work with in the next steps. The crawler returns a list of pairs of (_url_, _markdown_).\n",
    "\n",
    "### Embedding search\n",
    "\n",
    "To be filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### The next few cells show how to use the tools to find conservation area pages.\n",
    "\n",
    "You can define your own parameters, such as maximum depth, how many results you want to see and any scorers or filters. Below is a template showing how to defin each scorer/filter type correctly - all you need to do is change the keywords or patterns.\n",
    "\n",
    "You can also define a prompt - this is what will be used to get embeddings scores for a webpage. The more similar the prompt is to what a conservation area page usually looks like, the more accurate the results.\n",
    "\n",
    "Lastly, you can await the `process_council` function, which will run the functionality described above and print the results. You can use it for one council only or for a list of councils."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Template for how to define filters or scorers\n",
    "##### Pick the types you need and adjust their parameter (keywords, threshold, ...) and pass them to the crawler function.\n",
    "    keyword_scorer = {\n",
    "        \"keywords\": [\"conservation\", \"conservation area\", \"planning\", \"building\", \"urban\", \"heritage\", \"resident\"],\n",
    "        \"weight\": 0.8,\n",
    "    }\n",
    "        \n",
    "    filters=[\n",
    "        {\"type\": \"SEOFilter\", \"threshold\": 0.6, \"keywords\": [\"conservation\", \"area\", \"planning\", \"heritage\", \"resident\"]},\n",
    "        {\"type\": \"ContentRelevanceFilter\", \"query\": \"conservation area or planning data\", \"threshold\": 0.2},\n",
    "        {\"type\": \"ContentTypeFilter\", \"allowed_types\": [\"text/html\"]},\n",
    "        {\"type\": \"URLPatternFilter\", \"patterns\": [\"*conservation*\", \"*planning*\", \"*building*\"]},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Gedling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6\n",
    "num_results = 10\n",
    "filters = [\n",
    "    {\"type\": \"ContentTypeFilter\", \"allowed_types\": [\"text/html\"]},\n",
    "    {\n",
    "        \"type\": \"URLPatternFilter\",\n",
    "        \"patterns\": [\"*conservation*\", \"*planning*\", \"*building*\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# please write the prompt such that there is a curly bracket where the council\n",
    "# name will be inserted\n",
    "prompt = \"\"\"\n",
    "The text discusses conservation areas from the {} and includes data on \n",
    "planning data, areas, interactive maps, appraisals, notices, boundaries, \n",
    "links and similar.\n",
    "\"\"\"\n",
    "\n",
    "df = await process_council(\n",
    "    council_names=[\"Gedling\"],\n",
    "    max_depth=max_depth,\n",
    "    filters=filters,\n",
    "    prompt=prompt,\n",
    "    num_results=num_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### South Gloucestershire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6\n",
    "num_results = 10\n",
    "filters = [\n",
    "    {\"type\": \"ContentTypeFilter\", \"allowed_types\": [\"text/html\"]},\n",
    "    {\n",
    "        \"type\": \"URLPatternFilter\",\n",
    "        \"patterns\": [\"*conservation*\", \"*planning*\", \"*building*\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# please write the prompt such that there is a curly bracket where the council\n",
    "# name will be inserted\n",
    "prompt = \"\"\"\n",
    "The text discusses conservation areas from the {} and includes data on \n",
    "planning data, areas, interactive maps, appraisals, notices, boundaries, \n",
    "links and similar.\n",
    "\"\"\"\n",
    "\n",
    "await process_council(\n",
    "    council_names=[\"South Gloucestershire\"],\n",
    "    max_depth=max_depth,\n",
    "    filters=filters,\n",
    "    prompt=prompt,\n",
    "    num_results=num_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Bournemouth, Christchurch and Poole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6\n",
    "num_results = 10\n",
    "filters = [\n",
    "    {\"type\": \"ContentTypeFilter\", \"allowed_types\": [\"text/html\"]},\n",
    "    {\n",
    "        \"type\": \"URLPatternFilter\",\n",
    "        \"patterns\": [\"*conservation*\", \"*planning*\", \"*building*\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# please write the prompt such that there is a curly bracket where the council\n",
    "# name will be inserted\n",
    "prompt = \"\"\"\n",
    "The text discusses conservation areas from the {} and includes data on \n",
    "planning data, areas, interactive maps, appraisals, notices, boundaries, \n",
    "links and similar.\n",
    "\"\"\"\n",
    "\n",
    "await process_council(\n",
    "    council_names=[\"Bournemouth, Christchurch and Poole\"],\n",
    "    max_depth=max_depth,\n",
    "    filters=filters,\n",
    "    prompt=prompt,\n",
    "    num_results=num_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Warrington"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6\n",
    "num_results = 10\n",
    "filters = [\n",
    "    {\"type\": \"ContentTypeFilter\", \"allowed_types\": [\"text/html\"]},\n",
    "    {\n",
    "        \"type\": \"URLPatternFilter\",\n",
    "        \"patterns\": [\"*conservation*\", \"*planning*\", \"*building*\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# please write the prompt such that there is a curly bracket where the council\n",
    "# name will be inserted\n",
    "prompt = \"\"\"\n",
    "The text discusses conservation areas from the {} and includes data on \n",
    "planning data, areas, interactive maps, appraisals, notices, boundaries, \n",
    "links and similar.\n",
    "\"\"\"\n",
    "\n",
    "await process_council(\n",
    "    council_names=[\"Warrington\"],\n",
    "    max_depth=max_depth,\n",
    "    filters=filters,\n",
    "    prompt=prompt,\n",
    "    num_results=num_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Stoke on Trent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6\n",
    "num_results = 10\n",
    "filters = [\n",
    "    {\"type\": \"ContentTypeFilter\", \"allowed_types\": [\"text/html\"]},\n",
    "    {\n",
    "        \"type\": \"URLPatternFilter\",\n",
    "        \"patterns\": [\"*conservation*\", \"*planning*\", \"*building*\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# please write the prompt such that there is a curly bracket where the council\n",
    "# name will be inserted\n",
    "prompt = \"\"\"\n",
    "The text discusses conservation areas from the {} and includes data on \n",
    "planning data, areas, interactive maps, appraisals, notices, boundaries, \n",
    "links and similar.\n",
    "\"\"\"\n",
    "\n",
    "await process_council(\n",
    "    council_names=[\"Stoke\"],\n",
    "    max_depth=max_depth,\n",
    "    filters=filters,\n",
    "    prompt=prompt,\n",
    "    num_results=num_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Redbridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6\n",
    "num_results = 10\n",
    "filters = [\n",
    "    {\"type\": \"ContentTypeFilter\", \"allowed_types\": [\"text/html\"]},\n",
    "    {\n",
    "        \"type\": \"URLPatternFilter\",\n",
    "        \"patterns\": [\"*conservation*\", \"*planning*\", \"*building*\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# please write the prompt such that there is a curly bracket where the council\n",
    "# name will be inserted\n",
    "prompt = \"\"\"\n",
    "The text discusses conservation areas from the {} and includes data on \n",
    "planning data, areas, interactive maps, appraisals, notices, boundaries, \n",
    "links and similar.\n",
    "\"\"\"\n",
    "\n",
    "await process_council(\n",
    "    council_names=[\"Redbridge\"],\n",
    "    max_depth=max_depth,\n",
    "    filters=filters,\n",
    "    prompt=prompt,\n",
    "    num_results=num_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6\n",
    "num_results = 10\n",
    "filters = [\n",
    "    {\"type\": \"ContentTypeFilter\", \"allowed_types\": [\"text/html\"]},\n",
    "    {\n",
    "        \"type\": \"URLPatternFilter\",\n",
    "        \"patterns\": [r\"*[Cc]onservation*\", r\"*[Pp]lanning*\", r\"*[Bb]uilding*\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# please write the prompt such that there is a curly bracket where the council\n",
    "# name will be inserted\n",
    "prompt = \"\"\"\n",
    "The text discusses conservation areas from the {} and includes data on \n",
    "planning data, areas, interactive maps, appraisals, notices, boundaries, \n",
    "links and similar.\n",
    "\"\"\"\n",
    "\n",
    "await process_council(\n",
    "    council_names=[\"York\"],\n",
    "    max_depth=max_depth,\n",
    "    filters=filters,\n",
    "    prompt=prompt,\n",
    "    num_results=num_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Malvern Hills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6\n",
    "num_results = 10\n",
    "filters = [\n",
    "    {\"type\": \"ContentTypeFilter\", \"allowed_types\": [\"text/html\"]},\n",
    "    {\n",
    "        \"type\": \"URLPatternFilter\",\n",
    "        \"patterns\": [r\"*[Cc]onservation*\", r\"*[Pp]lanning*\", r\"*[Bb]uilding*\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# please write the prompt such that there is a curly bracket where the council\n",
    "# name will be inserted\n",
    "prompt = \"\"\"\n",
    "The text discusses conservation areas from the {} and includes data on \n",
    "planning data, areas, interactive maps, appraisals, notices, boundaries, \n",
    "links and similar.\n",
    "\"\"\"\n",
    "\n",
    "await process_council(\n",
    "    council_names=[\"Malvern Hills\"],\n",
    "    max_depth=max_depth,\n",
    "    filters=filters,\n",
    "    prompt=prompt,\n",
    "    num_results=num_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Multiple councils\n",
    "\n",
    "You can define any list of councils and their processing will be executed sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4321)\n",
    "num_examples = 10\n",
    "example_idx = np.random.randint(0, len(data), num_examples)\n",
    "examples = data[example_idx]\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6\n",
    "num_results = 10\n",
    "filters = [\n",
    "    {\"type\": \"ContentTypeFilter\", \"allowed_types\": [\"text/html\"]},\n",
    "    {\n",
    "        \"type\": \"URLPatternFilter\",\n",
    "        \"patterns\": [\"*conservation*\", \"*planning*\", \"*building*\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# please write the prompt such that there is a curly bracket where the council\n",
    "# name will be inserted\n",
    "prompt = \"\"\"\n",
    "The text discusses conservation areas from the {} and includes data on \n",
    "planning data, areas, interactive maps, appraisals, notices, boundaries, \n",
    "links and similar.\n",
    "\"\"\"\n",
    "\n",
    "await process_council(\n",
    "    council_names=examples.get_column(\"name\"),\n",
    "    max_depth=max_depth,\n",
    "    filters=filters,\n",
    "    prompt=prompt,\n",
    "    num_results=num_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
